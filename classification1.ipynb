{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 10])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([400, 1])\n",
      "torch.Size([100, 1])\n",
      "epoch : 1.00, loss : 0.7176\n",
      "epoch : 21.00, loss : 0.6879\n",
      "epoch : 41.00, loss : 0.6624\n",
      "epoch : 61.00, loss : 0.6322\n",
      "epoch : 81.00, loss : 0.5935\n",
      "epoch : 101.00, loss : 0.5459\n",
      "epoch : 121.00, loss : 0.4928\n",
      "epoch : 141.00, loss : 0.4403\n",
      "epoch : 161.00, loss : 0.3943\n",
      "epoch : 181.00, loss : 0.3576\n",
      "epoch : 201.00, loss : 0.3298\n",
      "epoch : 221.00, loss : 0.3092\n",
      "epoch : 241.00, loss : 0.2938\n",
      "epoch : 261.00, loss : 0.2821\n",
      "epoch : 281.00, loss : 0.2729\n",
      "epoch : 301.00, loss : 0.2656\n",
      "epoch : 321.00, loss : 0.2596\n",
      "epoch : 341.00, loss : 0.2543\n",
      "epoch : 361.00, loss : 0.2498\n",
      "epoch : 381.00, loss : 0.2457\n",
      "epoch : 401.00, loss : 0.2420\n",
      "epoch : 421.00, loss : 0.2386\n",
      "epoch : 441.00, loss : 0.2355\n",
      "epoch : 461.00, loss : 0.2326\n",
      "epoch : 481.00, loss : 0.2300\n",
      "epoch : 501.00, loss : 0.2275\n",
      "epoch : 521.00, loss : 0.2251\n",
      "epoch : 541.00, loss : 0.2229\n",
      "epoch : 561.00, loss : 0.2207\n",
      "epoch : 581.00, loss : 0.2186\n",
      "epoch : 601.00, loss : 0.2166\n",
      "epoch : 621.00, loss : 0.2147\n",
      "epoch : 641.00, loss : 0.2128\n",
      "epoch : 661.00, loss : 0.2110\n",
      "epoch : 681.00, loss : 0.2092\n",
      "epoch : 701.00, loss : 0.2075\n",
      "epoch : 721.00, loss : 0.2058\n",
      "epoch : 741.00, loss : 0.2042\n",
      "epoch : 761.00, loss : 0.2026\n",
      "epoch : 781.00, loss : 0.2011\n",
      "epoch : 801.00, loss : 0.1996\n",
      "epoch : 821.00, loss : 0.1982\n",
      "epoch : 841.00, loss : 0.1969\n",
      "epoch : 861.00, loss : 0.1955\n",
      "epoch : 881.00, loss : 0.1942\n",
      "epoch : 901.00, loss : 0.1928\n",
      "epoch : 921.00, loss : 0.1915\n",
      "epoch : 941.00, loss : 0.1902\n",
      "epoch : 961.00, loss : 0.1889\n",
      "epoch : 981.00, loss : 0.1877\n",
      "epoch : 1001.00, loss : 0.1865\n",
      "epoch : 1021.00, loss : 0.1852\n",
      "epoch : 1041.00, loss : 0.1841\n",
      "epoch : 1061.00, loss : 0.1829\n",
      "epoch : 1081.00, loss : 0.1817\n",
      "epoch : 1101.00, loss : 0.1806\n",
      "epoch : 1121.00, loss : 0.1795\n",
      "epoch : 1141.00, loss : 0.1783\n",
      "epoch : 1161.00, loss : 0.1772\n",
      "epoch : 1181.00, loss : 0.1761\n",
      "epoch : 1201.00, loss : 0.1751\n",
      "epoch : 1221.00, loss : 0.1740\n",
      "epoch : 1241.00, loss : 0.1730\n",
      "epoch : 1261.00, loss : 0.1719\n",
      "epoch : 1281.00, loss : 0.1709\n",
      "epoch : 1301.00, loss : 0.1699\n",
      "epoch : 1321.00, loss : 0.1689\n",
      "epoch : 1341.00, loss : 0.1679\n",
      "epoch : 1361.00, loss : 0.1669\n",
      "epoch : 1381.00, loss : 0.1659\n",
      "epoch : 1401.00, loss : 0.1649\n",
      "epoch : 1421.00, loss : 0.1640\n",
      "epoch : 1441.00, loss : 0.1630\n",
      "epoch : 1461.00, loss : 0.1621\n",
      "epoch : 1481.00, loss : 0.1611\n",
      "epoch : 1501.00, loss : 0.1601\n",
      "epoch : 1521.00, loss : 0.1592\n",
      "epoch : 1541.00, loss : 0.1582\n",
      "epoch : 1561.00, loss : 0.1573\n",
      "epoch : 1581.00, loss : 0.1564\n",
      "epoch : 1601.00, loss : 0.1554\n",
      "epoch : 1621.00, loss : 0.1545\n",
      "epoch : 1641.00, loss : 0.1536\n",
      "epoch : 1661.00, loss : 0.1527\n",
      "epoch : 1681.00, loss : 0.1518\n",
      "epoch : 1701.00, loss : 0.1509\n",
      "epoch : 1721.00, loss : 0.1500\n",
      "epoch : 1741.00, loss : 0.1492\n",
      "epoch : 1761.00, loss : 0.1483\n",
      "epoch : 1781.00, loss : 0.1474\n",
      "epoch : 1801.00, loss : 0.1464\n",
      "epoch : 1821.00, loss : 0.1455\n",
      "epoch : 1841.00, loss : 0.1446\n",
      "epoch : 1861.00, loss : 0.1437\n",
      "epoch : 1881.00, loss : 0.1428\n",
      "epoch : 1901.00, loss : 0.1419\n",
      "epoch : 1921.00, loss : 0.1410\n",
      "epoch : 1941.00, loss : 0.1401\n",
      "epoch : 1961.00, loss : 0.1393\n",
      "epoch : 1981.00, loss : 0.1384\n",
      "epoch : 2001.00, loss : 0.1375\n",
      "epoch : 2021.00, loss : 0.1367\n",
      "epoch : 2041.00, loss : 0.1358\n",
      "epoch : 2061.00, loss : 0.1349\n",
      "epoch : 2081.00, loss : 0.1341\n",
      "epoch : 2101.00, loss : 0.1332\n",
      "epoch : 2121.00, loss : 0.1323\n",
      "epoch : 2141.00, loss : 0.1315\n",
      "epoch : 2161.00, loss : 0.1306\n",
      "epoch : 2181.00, loss : 0.1298\n",
      "epoch : 2201.00, loss : 0.1289\n",
      "epoch : 2221.00, loss : 0.1280\n",
      "epoch : 2241.00, loss : 0.1272\n",
      "epoch : 2261.00, loss : 0.1263\n",
      "epoch : 2281.00, loss : 0.1255\n",
      "epoch : 2301.00, loss : 0.1246\n",
      "epoch : 2321.00, loss : 0.1238\n",
      "epoch : 2341.00, loss : 0.1229\n",
      "epoch : 2361.00, loss : 0.1221\n",
      "epoch : 2381.00, loss : 0.1212\n",
      "epoch : 2401.00, loss : 0.1204\n",
      "epoch : 2421.00, loss : 0.1196\n",
      "epoch : 2441.00, loss : 0.1187\n",
      "epoch : 2461.00, loss : 0.1179\n",
      "epoch : 2481.00, loss : 0.1171\n",
      "epoch : 2501.00, loss : 0.1163\n",
      "epoch : 2521.00, loss : 0.1154\n",
      "epoch : 2541.00, loss : 0.1146\n",
      "epoch : 2561.00, loss : 0.1138\n",
      "epoch : 2581.00, loss : 0.1130\n",
      "epoch : 2601.00, loss : 0.1121\n",
      "epoch : 2621.00, loss : 0.1113\n",
      "epoch : 2641.00, loss : 0.1105\n",
      "epoch : 2661.00, loss : 0.1097\n",
      "epoch : 2681.00, loss : 0.1089\n",
      "epoch : 2701.00, loss : 0.1081\n",
      "epoch : 2721.00, loss : 0.1073\n",
      "epoch : 2741.00, loss : 0.1065\n",
      "epoch : 2761.00, loss : 0.1057\n",
      "epoch : 2781.00, loss : 0.1049\n",
      "epoch : 2801.00, loss : 0.1041\n",
      "epoch : 2821.00, loss : 0.1032\n",
      "epoch : 2841.00, loss : 0.1024\n",
      "epoch : 2861.00, loss : 0.1017\n",
      "epoch : 2881.00, loss : 0.1009\n",
      "epoch : 2901.00, loss : 0.1001\n",
      "epoch : 2921.00, loss : 0.0993\n",
      "epoch : 2941.00, loss : 0.0986\n",
      "epoch : 2961.00, loss : 0.0978\n",
      "epoch : 2981.00, loss : 0.0970\n",
      "Test Accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_data = datasets.make_classification(n_samples=500, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "X,y = class_data\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32)).view(y_train.shape[0],1)\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).view(y_test.shape[0],1)\n",
    "\n",
    "n_samples, n_features = X_train.shape\n",
    "\n",
    "print((X_train.shape))\n",
    "print((X_test.shape))\n",
    "print((y_train.shape))\n",
    "print((y_test.shape))\n",
    "\n",
    "class complexmodel(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(complexmodel, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input_features, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = complexmodel(n_features)\n",
    "# hyperparameters\n",
    "epochs = 3000\n",
    "learning_rate = 0.03\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# model\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #forwarrd pass\n",
    "    y_pred = model.forward(X_train)\n",
    "\n",
    "    # loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    # clear grads\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # back pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update wt\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%20 == 0:\n",
    "        print(f'epoch : {epoch+1:.2f}, loss : {loss.item():.4f}')\n",
    "        \n",
    "\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test)\n",
    "    y_test_pred_classes = (y_test_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    correct_test = (y_test_pred_classes == y_test).sum().item()  # Count correct predictions\n",
    "    accuracy_test = correct_test / y_test.size(0)  # Compute accuracy\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_test:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
